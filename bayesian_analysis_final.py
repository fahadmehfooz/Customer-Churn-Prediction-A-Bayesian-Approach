# -*- coding: utf-8 -*-
"""Bayesian Analysis FINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sDcDq8a0Kab1DOzQXFZ9HhzRa7CSi-Uo

# **Bayesian Data Analysis: End Terem Project**

## **Customer Churn Analysis Using Bayesian and Frequentist Approaches**

**To predict customer churn and
analyze the factors contributing
to it using both Bayesian and
frequentist methods, providing
insights into uncertainty
quantification and the impact of
various features.**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import arviz as az
from scipy.stats import chi2_contingency, ttest_ind, kstest, bernoulli, binom, poisson, uniform, norm, expon, lognorm, gamma, stats
import pymc as pm
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score, log_loss, accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
from scipy.special import expit
from statsmodels.stats.proportion import proportions_ztest
from sklearn.linear_model import LogisticRegression
import statsmodels.api as sm
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats

# Load the data
df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')

df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df.dropna(inplace=True)
df.drop("customerID", axis=1, inplace=True)
df.reset_index(drop=True, inplace=True)
# Convert 'Churn' to binary
df['Churn'] = (df['Churn'] == 'Yes').astype(int)

5163/ (5163 + 1869)

df["Churn"].value_counts()

numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']

X = df.drop('Churn', axis=1)
y = df['Churn']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])
X_test[numerical_features] = scaler.transform(X_test[numerical_features])

df.columns

"""# **1.EDA**

### Distribution of churn rates across different features
"""

categorical_features = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',
                        'PhoneService', 'MultipleLines', 'InternetService',
                        'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
                        'TechSupport', 'StreamingTV', 'StreamingMovies',
                        'Contract', 'PaperlessBilling', 'PaymentMethod']

plt.figure(figsize=(20, 15))
for i, feature in enumerate(categorical_features, 1):
    plt.subplot(4, 4, i)
    df.groupby(feature)['Churn'].mean().plot(kind='bar')
    plt.title(f'Churn Rate by {feature}')
    plt.ylabel('Churn Rate')
    plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""### Observations:

> Churn rate is high for fiber optic internet service.

> Churn rate is high for people with no online security.

> Churn rate is high for people with no online backup.

> Churn rate is high for people with no device protection.

> Churn rate is high for people with no tech support.

> Churn rate is high for people with no streaming tv.

### Correlation plot
"""

# Correlation heatmap for numeric features
numeric_features = ['tenure', 'MonthlyCharges', 'TotalCharges']
corr_matrix = df[numeric_features + ['Churn']].corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

"""> Tenure and total charges have strong correlation.

> Monthly and total charges also have strong correlation.

### Boxplots for charges distribution across churned and non-churned customers
"""

plt.figure(figsize=(15, 5))
for i, feature in enumerate(numeric_features, 1):
    plt.subplot(1, 3, i)
    sns.boxplot(x='Churn', y=feature, data=df)
    plt.title(f'{feature} Distribution by Churn')
plt.tight_layout()
plt.show()

"""For tenure:

> Non-churned customers stay longer (median ~37 months vs ~10 months for churned)

> Higher churn risk in early months of service


For Monthly Charges:

> Churned customers pay more (median ~$80 vs ~$65 for non-churned)

> Wider spread of charges among churned customers

For Total Charges:

> Non-churned customers have higher total spend due to longer tenure

> More outliers in both groups, indicating high variability
"""

# Features to analyze
features = ['tenure', 'MonthlyCharges', 'TotalCharges']

# Plot setup
plt.figure(figsize=(12, 8))
for i, feature in enumerate(features):
    plt.subplot(3, 2, i * 2 + 1)
    sns.histplot(X_train[feature], kde=True, bins=30, color='skyblue')
    plt.title(f'{feature} - Histogram')

    plt.subplot(3, 2, i * 2 + 2)
    stats.probplot(X_train[feature].dropna(), dist="norm", plot=plt)
    plt.title(f'{feature} - Q-Q Plot')

plt.tight_layout()
plt.show()

"""# **2.Statistical Testing**

### 2.1 Test for Dependency Between Churn and Gender

Hypothesis:



Null Hypothesis (
𝐻0
​
 ): There is no association between Churn and gender.

Alternative Hypothesis (
𝐻A
​
 ): There is an association between Churn and gender.


Significance Level: *0.5*


Test:

Use the Chi-Square test of independence for categorical data.
"""

# Chi-Square Test for Gender and Churn
contingency_gender = pd.crosstab(df['gender'], df['Churn'])
chi2, p, dof, expected = stats.chi2_contingency(contingency_gender)

alpha = 0.05
print(f"Chi-Square Test (Gender vs Churn): Chi2 = {chi2:.4f}, p = {p:.4f}")
if p < alpha:
    print("Reject the null hypothesis: There is a significant association between Gender and Churn.")
else:
    print("Fail to reject the null hypothesis: No significant association between Gender and Churn.")

"""> No significant association between Gender and Churn.

### 2.2 Dependency Between Churn and Contract

Test: Chi-Square Test of Independence

Significance Level (
𝛼
α): 0.05

Hypotheses:

𝐻0
​
 : There is no association between Churn and Contract.

𝐻𝐴
​
 : There is an association between Churn and Contract.
"""

contingency_contract = pd.crosstab(df['Contract'], df['Churn'])
chi2, p, dof, expected = stats.chi2_contingency(contingency_contract)

print(f"Chi-Square Test (Contract vs Churn): Chi2 = {chi2:.4f}, p = {p:.4f}")
if p < alpha:
    print("Reject the null hypothesis: There is a significant association between Contract and Churn.")
else:
    print("Fail to reject the null hypothesis: No significant association between Contract and Churn.")

"""### 2.3 Difference in MonthlyCharges Between Churned and Non-Churned

Test: Independent Samples t-Test (Welch’s)

Significance Level (
𝛼
α): 0.05
Confidence Interval: 95%

Hypotheses:

𝐻0
​
 : The mean MonthlyCharges is the same for churned and non-churned customers.
𝐻𝐴
​
 : The mean MonthlyCharges is different for churned and non-churned customers.

"""

df.groupby("Churn")["MonthlyCharges"].mean()

# Check unique values in 'Churn'
print("Unique values in 'Churn':", df['Churn'].unique())

# Split data
churned = df[df['Churn'] == 1]['MonthlyCharges']
non_churned = df[df['Churn'] == 0]['MonthlyCharges']

# Check group sizes
print(f"Number of churned customers: {len(churned)}")
print(f"Number of non-churned customers: {len(non_churned)}")

# Ensure groups are non-empty
if len(churned) == 0 or len(non_churned) == 0:
    print("One of the groups is empty. Cannot perform the test.")
else:
    # Perform t-test
    t_stat, p = stats.ttest_ind(churned, non_churned, equal_var=False)

    # Calculate confidence interval for the mean difference
    mean_diff = churned.mean() - non_churned.mean()
    se_diff = np.sqrt(churned.var(ddof=1) / len(churned) + non_churned.var(ddof=1) / len(non_churned))
    dof = len(churned) + len(non_churned) - 2  # Degrees of freedom
    ci_low, ci_high = stats.t.interval(
        confidence=0.95,  # Confidence level
        df=dof,           # Degrees of freedom
        loc=mean_diff,    # Mean difference
        scale=se_diff     # Standard error of the difference
    )

    # Print results
    print(f"t-Test (Monthly Charges): t = {t_stat:.4f}, p = {p:.4f}")
    print(f"95% Confidence Interval: [{ci_low:.2f}, {ci_high:.2f}]")

    # Hypothesis conclusion
    alpha = 0.05
    if p < alpha:
        print("Reject the null hypothesis: MonthlyCharges differs significantly between churned and non-churned customers.")
    else:
        print("Fail to reject the null hypothesis: No significant difference in MonthlyCharges.")

"""### 2.4  Levene’s Test: Variance of Tenure Between Groups

Test: Levene’s Test for Equality of Variances


Significance Level (
𝛼
α): 0.05

Hypotheses:

𝐻0
​
 : Variance of tenure is the same for churned and non-churned customers.

𝐻𝐴
​
 : Variance of tenure is different for churned and non-churned customers.

"""

tenure_churned = df[df['Churn'] == 1]['tenure']
tenure_non_churned = df[df['Churn'] == 0]['tenure']
levene_stat, p = stats.levene(tenure_churned, tenure_non_churned)

print(f"Levene's Test (Tenure): Stat = {levene_stat:.4f}, p = {p:.4f}")
if p < alpha:
    print("Reject the null hypothesis: Variance of Tenure differs significantly between groups.")
else:
    print("Fail to reject the null hypothesis: No significant difference in Variance of Tenure.")

"""### 2.5  Proportion Z-Test: Difference in OnlineSecurity Proportions

Test: Two-Proportion Z-Test
Significance Level (
𝛼
α): 0.05
Confidence Interval: 95%

Hypotheses:

𝐻
0
​
 : The proportion of customers with OnlineSecurity is the same for churned and non-churned customers.


𝐻
𝐴
​
 : The proportion of customers with OnlineSecurity differs between churned and non-churned customers.
"""

churn_online_sec = df[df['Churn'] == 1]['OnlineSecurity'].value_counts()
non_churn_online_sec = df[df['Churn'] == 0]['OnlineSecurity'].value_counts()

count = [churn_online_sec['Yes'], non_churn_online_sec['Yes']]
nobs = [churn_online_sec.sum(), non_churn_online_sec.sum()]
z_stat, p = proportions_ztest(count, nobs)

print(f"Proportion Z-Test (Online Security): Z = {z_stat:.4f}, p = {p:.4f}")
if p < alpha:
    print("Reject the null hypothesis: Proportion of customers with OnlineSecurity differs between groups.")
else:
    print("Fail to reject the null hypothesis: No significant difference in proportions of OnlineSecurity.")

"""### 2.6 Pearson Correlation: TotalCharges and Tenure

Test: Pearson Correlation Coefficient
Significance Level (
𝛼
α): 0.05

Hypotheses:

𝐻
0
​
 : No correlation exists between TotalCharges and tenure.

𝐻
𝐴
​
 : A correlation exists between TotalCharges and tenure.
"""

correlation, p = stats.pearsonr(df['TotalCharges'], df['tenure'])

print(f"Pearson Correlation (TotalCharges vs Tenure): Correlation = {correlation:.4f}, p = {p:.4f}")
if p < alpha:
    print("Reject the null hypothesis: Significant correlation between TotalCharges and Tenure.")
else:
    print("Fail to reject the null hypothesis: No significant correlation between TotalCharges and Tenure.")

"""# **3. Data Preparation**"""

df["MultipleLines"] = df["MultipleLines"].replace("No phone service", "No")
df['Contract'] = df['Contract'].map({
    'Month-to-month': 0,
    'One year': 1,
    'Two year': 2
})



df['PaymentMethod'] = df['PaymentMethod'].map({
    'Electronic check': 0,
    'Mailed check': 1,
    'Bank transfer (automatic)': 2,
    'Credit card (automatic)': 3
})



df['gender'] = df['gender'].map({'Male': 1, 'Female': 0})
df['OnlineSecurity'] = df['OnlineSecurity'].map({'Yes': 1, 'No': 0, 'No internet service': 1})
df['OnlineBackup'] = df['OnlineBackup'].map({'Yes': 1, 'No': 0, 'No internet service': 0})
df['DeviceProtection'] = df['DeviceProtection'].map({'Yes': 1, 'No': 0, 'No internet service': 0})
df['TechSupport'] = df['TechSupport'].map({'Yes': 1, 'No': 0, 'No internet service': 0})
df['StreamingTV'] = df['StreamingTV'].map({'Yes': 1, 'No': 0, 'No internet service': 0})
df['StreamingMovies'] = df['StreamingMovies'].map({'Yes': 1, 'No': 0, 'No internet service': 0})

binary_cols = [col for col in df.columns if df[col].dtype =="object" and col!="InternetService"]


for col in binary_cols:
  df[col] = df[col].map({"Yes" : 1, "No" : 0})
df = pd.get_dummies(df, columns=["InternetService"], prefix="IS")

for col in ["IS_DSL", "IS_Fiber optic", "IS_No"]:
    df[col] = df[col].astype(int)

df.drop(["IS_No"], axis=1, inplace=True)

binary_cols = [col for col in df.columns if col not in ["tenure", "MonthlyCharges", "TotalCharges"]]

"""# **4. Testing and selecting appropriate priors**

**Prior is a probability distribution that represents your beliefs about a parameter before observing any data.**

## 4.1 Choosing Normal Priors For All Predictors

> Choosing normal distributions as priors for predicors.
"""

# Data Preparation
numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']
binary_features = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',
                   'MultipleLines', 'OnlineSecurity', 'OnlineBackup',
                   'DeviceProtection', 'TechSupport', 'StreamingTV',
                   'StreamingMovies', 'PhoneService', 'PaperlessBilling',
                   'IS_DSL', 'IS_Fiber optic']

X = df.drop('Churn', axis=1)
y = df['Churn']



# Performed stratified splitting to maintain same ratio of classes in train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y )


scaler = StandardScaler()
X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])
X_test[numerical_features] = scaler.transform(X_test[numerical_features])

with pm.Model() as manual_logistic_model:
    # Intercept
    intercept = pm.Normal('intercept', mu=0, sigma=1)

    # Coefficients for numerical features
    beta_tenure = pm.Normal('beta_tenure', mu=0, sigma=1)
    beta_monthly_charges = pm.Normal('beta_monthly_charges', mu=0, sigma=1)
    beta_total_charges = pm.Normal('beta_total_charges', mu=0, sigma=1)


    # Coefficients for binary features (Beta distributed)
    beta_gender = pm.Normal('beta_gender', mu=0, sigma=1)
    beta_senior_citizen = pm.Normal('beta_senior_citizen', mu=0, sigma=1)
    beta_partner = pm.Normal('beta_partner',  mu=0, sigma=1)
    beta_dependents = pm.Normal('beta_dependents',  mu=0, sigma=1)
    beta_multiple_lines = pm.Normal('beta_multiple_lines', mu=0, sigma=1)
    beta_online_security = pm.Normal('beta_online_security', mu=0, sigma=1)
    beta_online_backup = pm.Normal('beta_online_backup', mu=0, sigma=1)
    beta_device_protection = pm.Normal('beta_device_protection',mu=0, sigma=1)
    beta_tech_support = pm.Normal('beta_tech_support',mu=0, sigma=1)
    beta_streaming_tv = pm.Normal('beta_streaming_tv', mu=0, sigma=1)
    beta_streaming_movies = pm.Normal('beta_streaming_movies',mu=0, sigma=1)
    beta_is_dsl = pm.Normal('beta_is_dsl', mu=0, sigma=1)
    beta_is_fiber_optic = pm.Normal('beta_is_fiber_optic', mu=0, sigma=1)

    # Coefficients for other features
    beta_phone_service = pm.Normal('beta_phone_service', mu=0, sigma=1)
    beta_paperless_billing = pm.Normal('beta_paperless_billing',mu=0, sigma=1)

    # Linear combination
    linear_combination = (
        intercept +
        beta_tenure * X_train.tenure +
        beta_monthly_charges * X_train.MonthlyCharges +
        beta_total_charges * X_train.TotalCharges +
        beta_gender * X_train.gender +
        beta_senior_citizen * X_train.SeniorCitizen +
        beta_partner * X_train.Partner +
        beta_dependents * X_train.Dependents +
        beta_phone_service * X_train.PhoneService +
        beta_multiple_lines * X_train.MultipleLines +
        beta_online_security * X_train.OnlineSecurity +
        beta_online_backup * X_train.OnlineBackup +
        beta_device_protection * X_train.DeviceProtection +
        beta_tech_support * X_train.TechSupport +
        beta_streaming_tv * X_train.StreamingTV +
        beta_streaming_movies * X_train.StreamingMovies +
        beta_paperless_billing * X_train.PaperlessBilling +
        beta_is_dsl * X_train.IS_DSL +
        beta_is_fiber_optic * X_train['IS_Fiber optic']
    )

    # Likelihood
    likelihood = pm.invlogit(linear_combination)
    y_obs = pm.Bernoulli('y_obs', p=likelihood, observed=y_train)

    # Sampling using basic Metropolis-Hastings
    step = pm.Metropolis()
    trace_normal = pm.sample(
        tune=1000,
        draws=1000,
        chains=2,
        step=step,
        cores=3
    )

az.summary(trace_normal)

"""## Posterior Summary

**Distribution Measures:**

mean: The posterior mean (expected value) of each parameter

sd: The posterior standard deviation, showing uncertainty

hdi_3% and hdi_97%: The 94% Highest Density Interval bounds, showing the range
where 94% of the credible values lie

**Diagnostic Statistics:**

mcse_mean and mcse_sd: Monte Carlo Standard Error for mean and standard deviation

ess_bulk and ess_tail: Effective Sample Size for bulk and tail of the distributions

r_hat: Convergence diagnostic (all 1.0 indicating good convergence)

# Summary of Bayesian Model Diagnostics and Coefficient Interpretation

## 1. Convergence Issues (R-hat > 1.1)

Several predictors exhibit R-hat values greater than 1.1, indicating poor convergence in the posterior sampling process. This suggests that the model may not have explored the posterior distribution sufficiently for these parameters. The following coefficients show high R-hat values:

- **beta_is_dsl**
- **beta_is_fiber_optic**
- **beta_monthly_charges**
- **beta_phone_service**
- **beta_streaming_movies**
- **beta_streaming_tv**
- **beta_tenure**
- **beta_total_charges**
- **intercept**

These coefficients indicate potential issues in the model's sampling, likely due to the chosen priors or insufficient iterations.

## 2. Effective Sample Size (ESS)

Low ESS values suggest poor mixing of the Markov chains, or high autocorrelation between samples. This typically occurs when the priors are poorly specified or when the posterior distribution is hard to explore. The following parameters have low ESS:

- **beta_is_dsl**
- **beta_is_fiber_optic**
- **beta_monthly_charges**
- **beta_phone_service**
- **beta_streaming_movies**
- **beta_streaming_tv**
- **beta_tenure**
- **beta_total_charges**
- **intercept**

Further sampling or better prior specification is required to ensure reliable posterior estimates for these parameters.

## 3. Wide HDI Intervals

Parameters like **beta_is_fiber_optic**, **beta_monthly_charges**, **beta_tenure**, and **beta_total_charges** have wide HDI intervals, indicating a high degree of uncertainty in their estimation. These coefficients likely suffer from vague priors or insufficient data to produce precise estimates.

- **beta_is_fiber_optic** (HDI: [0.058, 1.149])
- **beta_monthly_charges** (HDI: [0.074, 0.715])
- **beta_tenure** (HDI: [-1.976, -1.449])
- **beta_total_charges** (HDI: [0.370, 1.005])

This suggests that the priors may need tightening or more data may be necessary for precise posterior estimation.

## 4. High Monte Carlo Standard Error (MCSE)

High MCSE values for several parameters indicate that more samples may be required to obtain reliable estimates for these coefficients:

- **beta_is_dsl**
- **beta_is_fiber_optic**
- **beta_monthly_charges**
- **beta_phone_service**

These parameters should be monitored with additional sampling to reduce the MCSE and improve the quality of the posterior estimates.

## 5. Positive Coefficients with Strong Influence

These coefficients have a positive association with the dependent variable:

- **beta_is_fiber_optic** (Mean = 0.680, HDI: [0.177, 1.240])  
  A strong positive influence, but the high uncertainty (wide HDI and poor convergence) suggests model adjustments are needed.
  
- **beta_monthly_charges** (Mean = 0.377, HDI: [0.020, 0.740])  
  A moderate positive effect, but the high R-hat and wide HDI indicate issues with convergence and posterior estimation.

- **beta_paperless_billing** (Mean = 0.365, HDI: [0.243, 0.508])  
  A positive, consistent effect with reliable estimates (low R-hat).

- **beta_senior_citizen** (Mean = 0.376, HDI: [0.190, 0.566])  
  Positive association with good posterior convergence and high ESS.

## 6. Negative Coefficients with Strong Influence

These coefficients show a negative association with the dependent variable:

- **beta_tenure** (Mean = -1.692, HDI: [-1.949, -1.407])  
  A strong negative influence with a well-defined posterior distribution.

- **beta_online_security** (Mean = -0.619, HDI: [-0.764, -0.449])  
  A substantial negative effect with reliable estimates.

- **beta_phone_service** (Mean = -0.871, HDI: [-1.177, -0.540])  
  A strong negative influence, but convergence issues (R-hat = 1.56).

- **beta_dependents** (Mean = -0.297, HDI: [-0.492, -0.104])  
  Moderate negative effect with good posterior reliability.

## 7. Mixed or Unclear Influence

These coefficients have HDIs that span zero, suggesting their influence may not be statistically significant:

- **beta_device_protection** (Mean = -0.160, HDI: [-0.310, 0.011])  
  Weak negative trend with high uncertainty.
  
- **beta_is_dsl** (Mean = 0.065, HDI: [-0.275, 0.416])  
  No significant effect due to high uncertainty.
  
- **beta_gender** (Mean = -0.042, HDI: [-0.165, 0.108])  
  Likely no effect given the HDI includes zero.
  
- **beta_streaming_movies** and **beta_streaming_tv**  
  Both have HDIs spanning zero, suggesting no clear effect.

## 8. Key Takeaways

1. **Convergence Issues:** Parameters with R-hat values greater than 1.1 need to be addressed through improved priors or more sampling.
   
2. **Wide HDIs:** Parameters such as **beta_is_fiber_optic** and **beta_monthly_charges** have wide HDIs, indicating high uncertainty. Priors may need tightening for better precision.

3. **Unclear Influence:** Parameters with HDIs spanning zero (**beta_device_protection**, **beta_gender**, **beta_streaming_movies**, **beta_streaming_tv**) should be revisited with better priors or adjusted for a clearer interpretation.

---

### Next Steps:
- **Adjust Priors:** Consider tightening priors for coefficients with wide HDIs.
- **Increase Sampling:** Run more iterations or adjust priors to address high R-hat values and improve convergence.
- **Reassess Model Fit:** Evaluate the model’s performance by examining potential data issues or the need for alternative modeling strategies.

## 4.2 Choosing New Priors According To Summary

## Improving our model: Choosing right priors for some predictors
"""

continuous_vars = ['tenure', 'MonthlyCharges', 'TotalCharges']
X_train_scaled = X_train.copy()
for var in continuous_vars:
    X_train_scaled[var] = (X_train[var] - X_train[var].mean()) / (2 * X_train[var].std())



with pm.Model() as cauchy_logistic_model:
    # Intercept
    intercept = pm.Cauchy('intercept', alpha=0, beta=10)
    beta_is_dsl = pm.Cauchy('beta_is_dsl', alpha=0, beta=2.5)
    beta_is_fiber_optic = pm.Cauchy('beta_is_fiber_optic', alpha=0, beta=2.5)
    beta_monthly_charges = pm.Cauchy('beta_monthly_charges', alpha=0, beta=2.5)
    beta_total_charges = pm.Cauchy('beta_total_charges', alpha=0, beta=2.5)

    # Coefficients for other features
    beta_phone_service = pm.Cauchy('beta_phone_service', alpha=0, beta=2.5)
    # Coefficients for numerical features
    beta_tenure = pm.Normal('beta_tenure', mu=0, sigma=1)


    # Coefficients for binary features
    beta_gender = pm.Normal('beta_gender', mu=0, sigma=1)
    beta_senior_citizen = pm.Normal('beta_senior_citizen', mu=0, sigma=1)
    beta_partner = pm.Normal('beta_partner', mu=0, sigma=1)
    beta_dependents = pm.Normal('beta_dependents', mu=0, sigma=1)
    beta_multiple_lines = pm.Normal('beta_multiple_lines', mu=0, sigma=1)
    beta_online_security = pm.Normal('beta_online_security', mu=0, sigma=1)
    beta_online_backup = pm.Normal('beta_online_backup', mu=0, sigma=1)
    beta_device_protection = pm.Normal('beta_device_protection', mu=0, sigma=1)
    beta_tech_support = pm.Normal('beta_tech_support', mu=0, sigma=1)
    beta_streaming_tv = pm.Normal('beta_streaming_tv', mu=0, sigma=1)
    beta_streaming_movies = pm.Normal('beta_streaming_movies', mu=0, sigma=1)
    beta_paperless_billing = pm.Normal('beta_paperless_billing', mu=0, sigma=1)

    # Linear combination
    linear_combination = (
        intercept +
        beta_tenure * X_train_scaled.tenure +
        beta_monthly_charges * X_train_scaled.MonthlyCharges +
        beta_total_charges * X_train_scaled.TotalCharges +
        beta_gender * X_train.gender +
        beta_senior_citizen * X_train.SeniorCitizen +
        beta_partner * X_train.Partner +
        beta_dependents * X_train.Dependents +
        beta_phone_service * X_train.PhoneService +
        beta_multiple_lines * X_train.MultipleLines +
        beta_online_security * X_train.OnlineSecurity +
        beta_online_backup * X_train.OnlineBackup +
        beta_device_protection * X_train.DeviceProtection +
        beta_tech_support * X_train.TechSupport +
        beta_streaming_tv * X_train.StreamingTV +
        beta_streaming_movies * X_train.StreamingMovies +
        beta_paperless_billing * X_train.PaperlessBilling +
        beta_is_dsl * X_train.IS_DSL +
        beta_is_fiber_optic * X_train['IS_Fiber optic']
    )

    # Likelihood
    likelihood = pm.invlogit(linear_combination)
    y_obs = pm.Bernoulli('y_obs', p=likelihood, observed=y_train)

    step = pm.Metropolis()
    cauchy_trace = pm.sample(
        tune=2000,
        draws=2000,
        chains=4,
        step=step,
        cores=3
    )


az.summary(cauchy_trace)

"""> With this model, ess bulk reduced than previous models. Also, rhat significantly increased. Both suggests cauchy is not working."""



"""### Priors Comparison: New vs. Earlier Priors

#### 1. **Convergence (R-hat)**
- **New Priors**: R-hat values are close to 1.00 for most parameters, indicating good convergence. The highest value is 3.38 for the intercept, suggesting potential issues with convergence for this parameter.
- **Earlier Priors**: The R-hat values are all close to 1.00, with the highest being 1.86, indicating a more stable convergence overall.

#### 2. **Effective Sample Size (ESS)**
- **New Priors**: ESS values are generally high, with many parameters having values over 500 for bulk ESS. However, some parameters (e.g., `beta_is_dsl`, `beta_is_fiber_optic`) have relatively low ESS values, indicating that the sampling may not be as effective for these parameters.
- **Earlier Priors**: ESS values are generally lower than with the new priors, particularly for parameters like `beta_is_fiber_optic` and `beta_is_dsl`, which had ESS values as low as 3.

#### 3. **Parameter Means and Standard Deviations**
- **New Priors**:
  - The means for most parameters are reasonable and fall within expected ranges. For example, `beta_monthly_charges` has a mean of 0.282, indicating a positive relationship with the target variable.
  - `beta_is_fiber_optic` has a much higher mean (1.205), indicating a stronger effect compared to other variables.
  - `beta_device_protection` shows a negative mean (-0.115), suggesting that it might have a diminishing effect on the target variable.
- **Earlier Priors**:
  - The parameter means are generally similar to those from the new priors. For instance, `beta_monthly_charges` has a mean of 0.421, which is slightly higher than the new prior’s estimate.
  - Parameters like `beta_device_protection` and `beta_is_dsl` have negative means, which align with the new priors.

#### 4. **HDI (Highest Density Interval)**
- **New Priors**: The HDI values for most parameters are narrow, indicating good precision. For example, the HDI for `beta_senior_citizen` is between 0.185 and 0.533, suggesting a moderate relationship.
- **Earlier Priors**: The HDI intervals are also narrow, with similar parameter estimates, such as `beta_senior_citizen` having an HDI of 0.190 to 0.537.

#### 5. **MCSE (Monte Carlo Standard Error)**
- **New Priors**: The MCSE values are mostly small, which is a good sign of stable sampling, especially for parameters with higher ESS. The MCSE is higher for parameters like `beta_is_fiber_optic` and `beta_phone_service`, indicating more variability in these estimates.
- **Earlier Priors**: MCSE values are similar in magnitude to the new priors, though some parameters have slightly larger MCSE values, indicating more variability in the earlier sampling process.

#### 6. **Implications of the Results**
- **New Priors**: The new priors appear to provide more stable and reliable estimates for the majority of parameters, with some room for improvement in terms of sampling efficiency (as evidenced by the lower ESS values for some parameters).
- **Earlier Priors**: The earlier priors resulted in relatively stable convergence, but the lower ESS values suggest that the model may not have explored the parameter space as effectively. The priors could be optimized further for better performance in future analyses.

#### 7. **Summary of Key Differences**
- The **new priors** tend to provide more reliable parameter estimates, with more effective sample sizes and lower MCSE values for many parameters.
- The **earlier priors** exhibited slightly higher variability in parameter estimates, particularly for parameters like `beta_is_fiber_optic`, which may require tuning for better convergence and sampling efficiency.

In conclusion, the **new priors** provide an overall improvement in the model’s stability, with more reliable estimates and better sampling efficiency, although certain parameters like the intercept may need further attention to improve convergence.

## 4.3 Evaluating The Model
"""

def predict(X, trace):
    posterior_means = {
        'intercept': trace.posterior['intercept'].mean().item(),
        'beta_tenure': trace.posterior['beta_tenure'].mean().item(),
        'beta_monthly_charges': trace.posterior['beta_monthly_charges'].mean().item(),
        'beta_total_charges': trace.posterior['beta_total_charges'].mean().item(),
        'beta_gender': trace.posterior['beta_gender'].mean().item(),
        'beta_senior_citizen': trace.posterior['beta_senior_citizen'].mean().item(),
        'beta_partner': trace.posterior['beta_partner'].mean().item(),
        'beta_dependents': trace.posterior['beta_dependents'].mean().item(),
        'beta_phone_service': trace.posterior['beta_phone_service'].mean().item(),
        'beta_multiple_lines': trace.posterior['beta_multiple_lines'].mean().item(),
        'beta_online_security': trace.posterior['beta_online_security'].mean().item(),
        'beta_online_backup': trace.posterior['beta_online_backup'].mean().item(),
        'beta_device_protection': trace.posterior['beta_device_protection'].mean().item(),
        'beta_tech_support': trace.posterior['beta_tech_support'].mean().item(),
        'beta_streaming_tv': trace.posterior['beta_streaming_tv'].mean().item(),
        'beta_streaming_movies': trace.posterior['beta_streaming_movies'].mean().item(),
        'beta_paperless_billing': trace.posterior['beta_paperless_billing'].mean().item(),
        'beta_is_dsl': trace.posterior['beta_is_dsl'].mean().item(),
        'beta_is_fiber_optic': trace.posterior['beta_is_fiber_optic'].mean().item()
    }

    coef = posterior_means

    linear_pred = (
        coef['intercept'] +
        coef['beta_tenure'] * X.tenure +
        coef['beta_monthly_charges'] * X.MonthlyCharges +
        coef['beta_total_charges'] * X.TotalCharges +
        coef['beta_gender'] * X.gender +
        coef['beta_senior_citizen'] * X.SeniorCitizen +
        coef['beta_partner'] * X.Partner +
        coef['beta_dependents'] * X.Dependents +
        coef['beta_phone_service'] * X.PhoneService +
        coef['beta_multiple_lines'] * X.MultipleLines +
        coef['beta_online_security'] * X.OnlineSecurity +
        coef['beta_online_backup'] * X.OnlineBackup +
        coef['beta_device_protection'] * X.DeviceProtection +
        coef['beta_tech_support'] * X.TechSupport +
        coef['beta_streaming_tv'] * X.StreamingTV +
        coef['beta_streaming_movies'] * X.StreamingMovies +
        coef['beta_paperless_billing'] * X.PaperlessBilling +
        coef['beta_is_dsl'] * X.IS_DSL +
        coef['beta_is_fiber_optic'] * X['IS_Fiber optic']
    )
    return expit(linear_pred)

def calculate_metrics(y_true, y_pred_prob):
    y_pred = (y_pred_prob > 0.5).astype(int)
    return {
        'Accuracy': accuracy_score(y_true, y_pred),
        'Precision': precision_score(y_true, y_pred),
        'Recall': recall_score(y_true, y_pred),
        'F1 Score': f1_score(y_true, y_pred),
        'ROC AUC': roc_auc_score(y_true, y_pred_prob)
    }

# Generate predictions
y_train_pred_prob = predict(X_train, trace_normal)
y_test_pred_prob = predict(X_test, trace_normal)

# Calculate metrics
train_metrics = calculate_metrics(y_train, y_train_pred_prob)
test_metrics = calculate_metrics(y_test, y_test_pred_prob)

# Create DataFrame with results
results_df_bayesian = pd.DataFrame({
    'Train': train_metrics,
    'Test': test_metrics
}).T

# Plot ROC curves
plt.figure(figsize=(10, 8))

# Training ROC
fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_prob)
roc_auc_train = auc(fpr_train, tpr_train)
plt.plot(fpr_train, tpr_train, 'b-', label=f'Train ROC (AUC = {roc_auc_train:.3f})')

# Testing ROC
fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred_prob)
roc_auc_test = auc(fpr_test, tpr_test)
plt.plot(fpr_test, tpr_test, 'r-', label=f'Test ROC (AUC = {roc_auc_test:.3f})')

# Plot diagonal line
plt.plot([0, 1], [0, 1], 'k--')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.grid(True)

# Display metrics
print("\nModel Evaluation Metrics:")
display(results_df_bayesian)

plt.show()

"""Likelihood function used here:

![image.png](data:image/png;base64,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)

### **5 Posterior Analysis**

### **5.1 Posterior Predictive Checks**
"""

variable_names = list(trace_normal.posterior.data_vars)

fig, axes = plt.subplots(nrows=len(variable_names), ncols=2, figsize=(12, 4*len(variable_names)))

pm.plot_trace(trace_normal, axes=axes)
plt.subplots_adjust(hspace=0.5, wspace=0.3)
plt.show()

"""# Analysis of Bayesian Model Parameters

The image contains density plots and trace plots for various parameters in a Bayesian model. Below is the analysis of the visualizations:

## **Density Plots**
- The density plots (left column) show the posterior distributions of each parameter.
- **Key Observations**:
  - Some parameters (e.g., `beta_is_fiber_optic`, `beta_monthly_charges`) exhibit well-defined, unimodal distributions, suggesting strong posterior certainty.
  - Others (e.g., `intercept`, `beta_dependents`) have broader or multimodal distributions, indicating uncertainty or convergence issues.

## **Trace Plots**
- The trace plots (right column) display the sampling chains over iterations.
- **Key Observations**:
  - Parameters like `beta_monthly_charges` and `beta_is_dsl` have good mixing, where the chains explore the parameter space evenly without strong autocorrelations.
  - For parameters like the `intercept` and `beta_total_charges`, the chains appear to stick or wander, showing potential convergence issues.

## **Overall Insights**
1. **Convergence Issues**:
   - Parameters such as the `intercept` and possibly `beta_total_charges` might require more iterations or adjusted priors, as their trace plots do not exhibit the "fuzzy caterpillar" appearance of well-converged chains.

2. **Well-Defined Parameters**:
   - Predictors like `beta_is_fiber_optic` and `beta_monthly_charges` show strong posterior certainty and good trace plot behavior, making them reliable predictors in the model.

3. **Potential Multimodality**:
   - Parameters such as `beta_dependents` and `beta_device_protection` may have multimodal distributions, potentially caused by insufficient sampling or model misspecification. These need further investigation.

4. **Autocorrelation**:
   - Some trace plots show correlated sampling (e.g., `beta_total_charges`), indicating inefficiency. Tuning sampling parameters or improving priors could help.

## **Action Items**
- **Increase Iterations**: Run the sampler for more iterations to improve convergence for problematic parameters.
- **Refine Priors**: Adjust priors for parameters with high uncertainty or poor convergence (e.g., `intercept`).
- **Posterior Predictive Checks**: Validate the model fit by comparing posterior predictions with the observed data.
- **Diagnostics**: Use tools like R-hat and Effective Sample Size (ESS) to quantify convergence issues and assess model behavior quantitatively.


"""

az.plot_pair(trace_normal, figsize=(24, 24), marginals=True)
plt.tight_layout(pad=2.0)
plt.show()

pm.plot_posterior(trace_normal);

"""# Key Takeaways from Posterior Distributions

1. **Strongly Influential Parameters**:
   - `beta_tenure` (mean ≈ -1.7): Strong negative effect with high certainty (narrow HDI).
   - `beta_total_charges` (mean ≈ 0.65): Strong positive effect with clear posterior definition.

2. **High Certainty Parameters**:
   - `beta_gender`, `beta_multiple_lines`, and `beta_online_backup` have narrow HDI ranges, reflecting strong certainty.

3. **Multimodality in Posteriors**:
   - Parameters like `beta_is_fiber_optic` and `beta_paperless_billing` exhibit multimodal distributions, indicating potential interactions or insufficient data.

4. **Wide Uncertainty**:
   - `beta_tech_support` and `beta_senior_citizen` show broader HDI ranges, reflecting greater uncertainty.

5. **Intercept**:
   - Mean ≈ -0.76 with moderate uncertainty, indicating its effect is not as well-defined.

6. **Recommendations**:
   - Investigate multimodal parameters further to address potential issues.
   - Leverage high-certainty coefficients for actionable insights.


"""

with manual_logistic_model:
    # Generate posterior predictive samples
    ppc = pm.sample_posterior_predictive(trace_normal, random_seed=42)

    # Access predictive samples for 'y_obs' from the posterior_predictive dataset
    y_pred = ppc["posterior_predictive"]["y_obs"].values  # Extract the NumPy array

    # Calculate observed test statistic: mean of y_train
    T_obs = np.mean(y_train)  # Replace `y_train` with your actual observed data

    # Simulated test statistics: mean across posterior samples
    T_sim = np.mean(y_pred, axis=(0, 2))  # Average across chain and y_obs_dim_2 dimensions

    # Flatten the T_sim array for the histogram plot
    T_sim_flat = T_sim.flatten()

    # Calculate Posterior Predictive p-value (PPP)
    ppp_value = np.mean(T_sim_flat >= T_obs)

    # Visualization of PPC
    plt.figure(figsize=(10, 6))
    plt.hist(T_sim_flat, bins=30, alpha=0.5, label='Posterior Predictive Means', color='skyblue', edgecolor='black')
    plt.axvline(T_obs, color='red', linestyle='--', linewidth=2, label=f'Observed Mean: {T_obs:.2f}')
    plt.title('Posterior Predictive Check')
    plt.xlabel('Simulated Mean')
    plt.ylabel('Frequency')
    plt.legend()
    plt.grid(alpha=0.3)
    plt.show()

    # Print PPP value
    print(f"Posterior Predictive p-value (PPP): {ppp_value:.4f}")

"""### Interpretation of the Posterior Predictive Check Plot

1. **Overview of the Plot**:
   - The histogram represents the **distribution of the mean** of the simulated data (posterior predictive samples).
   - The **red dashed line** indicates the mean of the **observed data** (\(y_{\text{obs}}\)), labeled as `0.27`.

---

2. **Key Observations**:
   - The distribution of posterior predictive means is approximately **centered around 0.265**, slightly below the observed mean.
   - The observed mean (red dashed line) lies within the bulk of the posterior predictive distribution, suggesting a reasonable fit.
   - There is no extreme deviation between the observed and predicted values, indicating the model can replicate the overall mean of the data.

---

3. **Key Takeaways**:
   - **Model Fit**: The observed mean is consistent with the predictions from the model's posterior distribution. This suggests the model is capable of capturing the central tendency of the data.
   - **Uncertainty Representation**: The spread of the posterior predictive means reflects the model's uncertainty in estimating the mean of new data. This uncertainty appears reasonable and aligns well with the observed data.
   - **Potential Refinements**: If further alignment is desired, consider:
     - Adding features or improving the priors if the mismatch is meaningful for the problem context.
     - Verifying the likelihood function matches the data distribution.

---

### Conclusion
The posterior predictive check indicates that the model provides a good approximation of the observed data. While minor differences exist, they are likely within acceptable limits, showing the model captures key patterns in the data.

### **5.2 Estimating Odds Ratio**

> Odds ratios provide a more intuitive interpretation of the effects in logistic regression compared to raw coefficients


> They represent the multiplicative change in odds of the outcome for a one-unit increase in the predictor variable

> Values greater than 1 indicate increased odds, while values less than 1 indicate decreased odds
"""

posterior_samples = trace_normal.posterior

# Calculate odds ratios
odds_ratios = {}
for var in posterior_samples.data_vars:
    if var != 'intercept' and var != 'y_obs':  # Exclude intercept and observed data
        odds_ratio = np.exp(posterior_samples[var].values)
        odds_ratios[var] = odds_ratio


# Calculate summary statistics for odds ratios
odds_ratio_summary = {}
for var, or_samples in odds_ratios.items():
    mean_or = np.mean(or_samples)
    median_or = np.median(or_samples)
    ci_lower = np.percentile(or_samples, 2.5)
    ci_upper = np.percentile(or_samples, 97.5)
    odds_ratio_summary[var] = {
        'mean': mean_or,
        'median': median_or,
        '2.5%': ci_lower,
        '97.5%': ci_upper
    }

# Convert to DataFrame for easier viewing
odds_ratio_df = pd.DataFrame(odds_ratio_summary).T

print(odds_ratio_df)

"""**Strongest Positive Associations**

> Fiber Optic Service: Highest impact with OR=2.72 (CI: 0.59-7.92), suggesting nearly 3x higher odds of churn, though with wide uncertainty

> Total Charges: OR=1.86 (CI: 1.34-2.53), indicating 86% higher odds

> Monthly Charges: OR=1.52 (CI: 0.71-2.88), showing 52% increased odds

**Moderate Positive Associations**


> Senior Citizen: OR=1.44 (CI: 1.20-1.72), 44% higher odds

> Paperless Billing: OR=1.42 (CI: 1.21-1.66), 42% higher odds

> Multiple Lines: OR=1.27 (CI: 1.02-1.55), 27% higher odds

> DSL: OR=1.21 (CI: 0.54-2.43), though with considerable uncertainty

**Strong Protective Factors**


> Phone Service: OR=0.42 (CI: 0.24-0.67), reduces odds by 58%

> Tech Support: OR=0.53 (CI: 0.42-0.65), reduces odds by 47%

> Online Security: OR=0.54 (CI: 0.44-0.67), reduces odds by 46%

> Tenure: OR=0.19 (CI: 0.14-0.26), strongest protective factor, reducing odds by 81%
"""

# Plot forest plot of odds ratios
az.plot_forest(odds_ratios, kind='forestplot', combined=True, hdi_prob=0.95)

"""### Key Takeaways

1. **Strong Predictors**:
   - **`beta_is_fiber_optic`** and **`beta_total_charges`** are the strongest predictors with high mean values and large effect sizes.
   - Policies or actions focusing on these variables could have the most substantial impact on the outcome.

2. **Moderate Predictors**:
   - Variables like **`beta_monthly_charges`**, **`beta_senior_citizen`**, and **`beta_multiple_lines`** show moderate influence on the outcome.
   - These should also be considered in decision-making as they provide significant contributions.

3. **Weak Predictors**:
   - Predictors such as **`beta_tenure`** and **`beta_phone_service`** have relatively minor effects and may not be critical to focus on for optimization.

4. **Uncertainty in Estimates**:
   - Variables with wider 95% HDI intervals, such as **`beta_is_fiber_optic`**, indicate higher uncertainty in their effect sizes.
   - This warrants further analysis or additional data collection to improve the reliability of these estimates.

5. **Positive Effects**:
   - All variables exhibit positive effects, as their 95% HDI intervals do not cross zero.
   - This suggests that all predictors positively contribute to the outcome to varying degrees.

## 6. Frequentist approach
"""

# Fit logistic regression model
model = LogisticRegression(random_state=42)
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1]


# For more detailed statistics, use statsmodels
X_train_sm = sm.add_constant(X_train)
sm_model = sm.Logit(y_train, X_train_sm).fit()

# Print summary
print(sm_model.summary())

# Calculate odds ratios
odds_ratios = np.exp(sm_model.params)
conf_int = np.exp(sm_model.conf_int())

# Create a DataFrame with odds ratios and confidence intervals
odds_ratio_df = pd.DataFrame({
    'Odds Ratio': odds_ratios,
    'Lower CI': conf_int[0],
    'Upper CI': conf_int[1]
})

print("\nOdds Ratios:")
print(odds_ratio_df)

# Calculate metrics for both train and test sets
def calculate_metrics(y_true, y_pred, y_pred_proba):
    return {
        'Accuracy': accuracy_score(y_true, y_pred),
        'Precision': precision_score(y_true, y_pred),
        'Recall': recall_score(y_true, y_pred),
        'F1 Score': f1_score(y_true, y_pred),
        'ROC AUC': roc_auc_score(y_true, y_pred_proba)
    }

# Generate predictions for train set
y_train_pred = model.predict(X_train)
y_train_pred_proba = model.predict_proba(X_train)[:, 1]

# Calculate metrics
train_metrics = calculate_metrics(y_train, y_train_pred, y_train_pred_proba)
test_metrics = calculate_metrics(y_test, y_pred, y_pred_proba)

# Create DataFrame with results
results_df_frequentist = pd.DataFrame({
    'Train': train_metrics,
    'Test': test_metrics
}).T

# Plot ROC curves
plt.figure(figsize=(10, 8))

# Training ROC
fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)
roc_auc_train = auc(fpr_train, tpr_train)
plt.plot(fpr_train, tpr_train, 'b-', label=f'Train ROC (AUC = {roc_auc_train:.3f})')

# Testing ROC
fpr_test, tpr_test, _ = roc_curve(y_test, y_pred_proba)
roc_auc_test = auc(fpr_test, tpr_test)
plt.plot(fpr_test, tpr_test, 'r-', label=f'Test ROC (AUC = {roc_auc_test:.3f})')

# Plot diagonal line
plt.plot([0, 1], [0, 1], 'k--')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.grid(True)

# Display metrics
print("\nModel Evaluation Metrics:")
display(results_df_frequentist)

plt.show()

results_df_bayesian

"""**On the basis of metrics, models from both the approaches are performing nearly
the same.**
"""